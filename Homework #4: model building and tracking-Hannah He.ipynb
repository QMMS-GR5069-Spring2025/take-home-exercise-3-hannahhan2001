{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8dd5fa-aa62-4047-bb39-0ab6bcee8bc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow pandas scikit-learn matplotlib seaborn\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a782bd04-32a7-4c37-9cfd-c068b9cf9294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md-sandbox\n",
    "# MAGIC <div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-4/mlflow-tracking.png\" style=\"height: 400px; margin: 20px\"/></div>\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC Import a dataset of Airbnb listings and featurize the data.  We'll use this to train a model.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# COMMAND ----------\n",
    "df_results = spark.read.csv('s3://columbia-gr5069-main/raw/results.csv', header=True)\n",
    "\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "169467c8-4f86-46e1-afa0-acfc88d72cd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean = df_results[[\"grid\", \"laps\", \"number\", \"resultId\", \"statusId\", \"positionOrder\"]]\n",
    "df_clean = df_clean.dropna()\n",
    "df_clean = df_clean.toPandas()\n",
    "\n",
    "X = df_clean.drop([\"positionOrder\"], axis=1)\n",
    "y = df_clean[[\"positionOrder\"]]\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "066b90b0-af0d-4fa9-ab14-72284d1fdb48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Clean the dataset\n",
    "X_train = X_train.replace('\\\\N', np.nan).dropna()\n",
    "y_train = y_train.replace('\\\\N', np.nan).dropna()\n",
    "X_test = X_test.replace('\\\\N', np.nan).dropna()\n",
    "y_test = y_test.replace('\\\\N', np.nan).dropna()\n",
    "\n",
    "# Ensure consistent lengths\n",
    "X_train, y_train = X_train.align(y_train, join='inner', axis=0)\n",
    "X_test, y_test = X_test.align(y_test, join='inner', axis=0)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Basic RF Experiment\") as run:\n",
    "  # Create model, train it, and create predictions\n",
    "  rf = RandomForestRegressor()\n",
    "  rf.fit(X_train, y_train)\n",
    "  predictions = rf.predict(X_test)\n",
    "  \n",
    "  # Log model\n",
    "  mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "  \n",
    "  # Create metrics\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  print(\"  mse: {}\".format(mse))\n",
    "  \n",
    "  # Log metrics\n",
    "  mlflow.log_metric(\"mse\", mse)\n",
    "  \n",
    "  runID = run.info.run_uuid\n",
    "  experimentID = run.info.experiment_id\n",
    "  \n",
    "  print(\"Inside MLflow Run with run_id {} and experiment_id {}\".format(runID, experimentID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2218b73f-ca5b-42b1-a030-b2b6e5b77a5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def log_rf(experimentID, run_name, params, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run(experiment_id=experimentID, run_name=run_name) as run:\n",
    "        # Initialize the model with hyperparameters\n",
    "        model = RandomForestRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, \"random-forest-model\")\n",
    "\n",
    "        # Log hyperparameters\n",
    "        for k, v in params.items():\n",
    "            mlflow.log_param(k, v)\n",
    "\n",
    "        # Create metrics\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        print(f\"  mse: {mse}\")\n",
    "        print(f\"  mae: {mae}\")\n",
    "        print(f\"  R2: {r2}\")\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"mae\", mae)  \n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "        # Create and log a plot of feature importances\n",
    "        feature_importances = model.feature_importances_\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.barplot(x=X_train.columns, y=feature_importances)\n",
    "        plt.title('Feature Importance')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot to the current directory\n",
    "        plot_path = \"feature_importance_plot.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        mlflow.log_artifact(plot_path)\n",
    "        \n",
    "        # Log predictions as CSV\n",
    "        predictions_df = pd.DataFrame({'True Values': y_test, 'Predicted Values': y_pred})\n",
    "        csv_path = \"predictions.csv\"\n",
    "        predictions_df.to_csv(csv_path, index=False)\n",
    "        mlflow.log_artifact(csv_path)\n",
    "        \n",
    "        return mlflow.active_run().info.run_id, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47fa6a8f-712d-46d5-a129-aba0f3cb07d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Example hyperparameters (you can tweak these for better tuning)\n",
    "param_grid = [\n",
    "    {\"n_estimators\": 30, \"max_depth\": 3, \"random_state\": 42},\n",
    "    {\"n_estimators\": 80, \"max_depth\": 8, \"random_state\": 42},\n",
    "    {\"n_estimators\": 120, \"max_depth\": 5, \"random_state\": 42},\n",
    "    {\"n_estimators\": 170, \"max_depth\": 12, \"random_state\": 42},\n",
    "    {\"n_estimators\": 60, \"max_depth\": 10, \"random_state\": 42},\n",
    "    {\"n_estimators\": 150, \"max_depth\": 6, \"random_state\": 42},\n",
    "    {\"n_estimators\": 90, \"max_depth\": 15, \"random_state\": 42},\n",
    "    {\"n_estimators\": 110, \"max_depth\": 7, \"random_state\": 42},\n",
    "    {\"n_estimators\": 40, \"max_depth\": 4, \"random_state\": 42},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 20, \"random_state\": 42}\n",
    "]\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "experimentID = \"f7f3c067e6c04249ab931221fd117ba1\"  # Replace with actual experiment ID\n",
    "\n",
    "best_run_uuid = None\n",
    "best_r2 = -float('inf')  # Initialize the best RÂ² value to negative infinity\n",
    "\n",
    "# Define the log_rf function\n",
    "def log_rf(experimentID, run_name, params, X_train, X_test, y_train, y_test):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import r2_score\n",
    "    import mlflow\n",
    "    import pandas as pd\n",
    "\n",
    "    with mlflow.start_run(experiment_id=experimentID, run_name=run_name) as run:\n",
    "        rf = RandomForestRegressor(**params)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        \n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mlflow.log_param(\"n_estimators\", params[\"n_estimators\"])\n",
    "        mlflow.log_param(\"max_depth\", params[\"max_depth\"])\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        \n",
    "        # Log predictions as CSV\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'True Values': y_test.flatten(), \n",
    "            'Predicted Values': y_pred.flatten()\n",
    "        })\n",
    "        csv_path = \"predictions.csv\"\n",
    "        predictions_df.to_csv(csv_path, index=False)\n",
    "        mlflow.log_artifact(csv_path)\n",
    "        \n",
    "        return run.info.run_uuid, r2\n",
    "\n",
    "# Loop over the hyperparameter grid to run 10 experiments\n",
    "for i, params in enumerate(param_grid):\n",
    "    run_name = f\"Run {i+1}\"\n",
    "    run_uuid, r2 = log_rf(experimentID, run_name, params, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    print(f\"Run {i+1} finished with RÂ²: {r2}. Run ID: {run_uuid}\")\n",
    "    \n",
    "    # Track the best model\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_run_uuid = run_uuid\n",
    "\n",
    "print(f\"\\nBest model run UUID: {best_run_uuid} with RÂ²: {best_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fa3cd85-22ba-4a98-b5af-85bcc5c73c8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Homework #4: model building and tracking-Hannah He",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
