{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8dd5fa-aa62-4047-bb39-0ab6bcee8bc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow pandas scikit-learn matplotlib seaborn\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a782bd04-32a7-4c37-9cfd-c068b9cf9294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "df_results = spark.read.csv('s3://columbia-gr5069-main/raw/results.csv', header=True)\n",
    "\n",
    "display(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "169467c8-4f86-46e1-afa0-acfc88d72cd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean = df_results[[\"grid\", \"laps\", \"points\", \"laps\", \"statusId\", \"positionOrder\"]]\n",
    "df_clean = df_clean.dropna()\n",
    "df_clean = df_clean.toPandas()\n",
    "\n",
    "X = df_clean.drop([\"positionOrder\"], axis=1)\n",
    "y = df_clean[[\"positionOrder\"]]\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca03d767-7926-4094-98a6-3f5233262a08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Clean the dataset by replacing non-numeric values with NaN and then filling them\n",
    "def clean_data(df):\n",
    "    df.replace(\"\\\\N\", np.nan, inplace=True)\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "    return df\n",
    "\n",
    "# Assuming you have already defined X_train, X_test, y_train, y_test\n",
    "X_train = clean_data(X_train)\n",
    "X_test = clean_data(X_test)\n",
    "y_train = clean_data(y_train)\n",
    "y_test = clean_data(y_test)\n",
    "\n",
    "# Define the param_grid with the modified hyperparameters\n",
    "param_grid = [\n",
    "    {\"n_estimators\": 30, \"max_depth\": 3, \"random_state\": 42},\n",
    "    {\"n_estimators\": 80, \"max_depth\": 8, \"random_state\": 42},\n",
    "    {\"n_estimators\": 120, \"max_depth\": 5, \"random_state\": 42},\n",
    "    {\"n_estimators\": 170, \"max_depth\": 12, \"random_state\": 42},\n",
    "    {\"n_estimators\": 60, \"max_depth\": 10, \"random_state\": 42},\n",
    "    {\"n_estimators\": 150, \"max_depth\": 6, \"random_state\": 42},\n",
    "    {\"n_estimators\": 90, \"max_depth\": 15, \"random_state\": 42},\n",
    "    {\"n_estimators\": 110, \"max_depth\": 7, \"random_state\": 42},\n",
    "    {\"n_estimators\": 40, \"max_depth\": 4, \"random_state\": 42},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 20, \"random_state\": 42}\n",
    "]\n",
    "\n",
    "# Function to log and train the model, and return the R² value\n",
    "def log_rf(experimentID, run_name, params, X_train, X_test, y_train, y_test):\n",
    "    with mlflow.start_run(experiment_id=experimentID, run_name=run_name):\n",
    "        # Initialize the model with parameters\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            random_state=params[\"random_state\"]\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        # Log hyperparameters\n",
    "        mlflow.log_param(\"n_estimators\", params[\"n_estimators\"])\n",
    "        mlflow.log_param(\"max_depth\", params[\"max_depth\"])\n",
    "        mlflow.log_param(\"random_state\", params[\"random_state\"])\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"mean_squared_error\", mse)\n",
    "        mlflow.log_metric(\"r2_score\", r2)\n",
    "        mlflow.log_metric(\"mean_absolute_error\", mae)\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        # Create and log a plot of feature importances\n",
    "        feature_importances = model.feature_importances_\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.barplot(x=X_train.columns, y=feature_importances)\n",
    "        plt.title('Feature Importance')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot to the current directory\n",
    "        plot_path = \"feature_importance_plot.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        mlflow.log_artifact(plot_path)\n",
    "        \n",
    "        # Log predictions as CSV\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'True Values': y_test.values.ravel(), \n",
    "            'Predicted Values': y_pred.ravel()\n",
    "        })\n",
    "        csv_path = \"predictions.csv\"\n",
    "        predictions_df.to_csv(csv_path, index=False)\n",
    "        mlflow.log_artifact(csv_path)\n",
    "        \n",
    "        return mlflow.active_run().info.run_id, r2\n",
    "\n",
    "# Define experiment ID (replace with actual experiment ID)\n",
    "experimentID = \"f7f3c067e6c04249ab931221fd117ba1\"  # Replace with actual experiment ID\n",
    "\n",
    "best_run_uuid = None\n",
    "best_r2 = -float('inf')  # Initialize the best R² value to negative infinity\n",
    "\n",
    "# Loop over the hyperparameter grid to run 10 experiments\n",
    "for i, params in enumerate(param_grid):\n",
    "    run_name = f\"Run {i+1}\"\n",
    "    print(f\"Running {run_name} with params: {params}\")\n",
    "    \n",
    "    run_uuid, r2 = log_rf(experimentID, run_name, params, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    print(f\"Run {i+1} finished with R²: {r2}. Run ID: {run_uuid}\")\n",
    "    \n",
    "    # Track the best model\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_run_uuid = run_uuid\n",
    "\n",
    "# Check if the best model was found\n",
    "if best_run_uuid is None:\n",
    "    print(\"No valid model found with R² greater than -inf\")\n",
    "else:\n",
    "    print(f\"\\nBest model run UUID: {best_run_uuid} with R²: {best_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1024608-80c2-4c82-a34a-b22fde98481a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Homework #4: model building and tracking-Hannah He",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
